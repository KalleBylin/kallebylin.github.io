[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Kalle Bylin",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Book: Prediction Machines\n\n\n\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\n\n\n\nJul 30, 2022\n\n\nKalle Bylin\n\n\n\n\n\n\n  \n\n\n\n\nA More Beautiful Question\n\n\n\n\n\n\n\nBooks\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2021\n\n\nKalle Bylin\n\n\n\n\n\n\n  \n\n\n\n\nSmart Business\n\n\n\n\n\n\n\nBooks\n\n\nLeadership\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2021\n\n\nKalle Bylin\n\n\n\n\n\n\n  \n\n\n\n\nComputational Learning Theory - Notes\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\nMar 9, 2021\n\n\nKalle Bylin\n\n\n\n\n\n\n  \n\n\n\n\nDeep Learning - Notes\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2021\n\n\nKalle Bylin\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-03-09-computational-learning-theory/2021-03-09-computational-learning-theory.html",
    "href": "posts/2021-03-09-computational-learning-theory/2021-03-09-computational-learning-theory.html",
    "title": "Computational Learning Theory - Notes",
    "section": "",
    "text": "A short summary of Computational Learning Theory."
  },
  {
    "objectID": "posts/2021-03-09-computational-learning-theory/2021-03-09-computational-learning-theory.html#is-bias-always-a-bad-thing",
    "href": "posts/2021-03-09-computational-learning-theory/2021-03-09-computational-learning-theory.html#is-bias-always-a-bad-thing",
    "title": "Computational Learning Theory - Notes",
    "section": "Is bias always a bad thing?",
    "text": "Is bias always a bad thing?\nBias usually has a very negative connotation, often thought of as prejudice and we are encouraged to always keep an open mind.\nBut don’t confuse an open mind with an empty mind. We often learn by building new ideas on top of other ideas we have learned in the past. Keeping an open mind means that we have to remember that some of our foundational building blocks might be wrong and need to be corrected. But constantly throwing away previous knowledge would make learning practically impossible.\nPigeon superstition\nOne of B.F. Skinner’s classical experiments supposedly showed “superstitious” behavior by pigeons. The experiment consisted in providing food to hungry pigeons in a cage through a mechanism that was guaranteed to be completely independent from any behavior by the pigeons.\n\n“If a clock is now arranged to present the food hopper at regular intervals with no reference whatsoever to the bird’s behavior, operant conditioning usually takes place. The bird tends to learn whatever response it is making when the hopper appears. The response may be extinguished and reconditioned. The experiment might be said to demonstrate a sort of superstition. The bird behaves as if there were a causal relation between its behavior and the presentation of food, although such a relation is lacking”.\n\nSkinner, B. F. (1948). ‘Superstition’ in the pigeon. Journal of Experimental Psychology, 38(2), 168–172.\nLet’s say one of the pigeons was pecking on a prticular stain on the bottom of the cage when the first round of food was released. According to Skinner, the pigeon was then more likely to repeat this same behavior which, in turn, also made it more likely for the pigeon to be found pecking on the stain when the next round of food was released.\nAmusingly, each pigeon showed a different type of behavior that was reinforced (walking around the cage in a specific direction, bobbing the head, etc.) as if the behavior was causing more food to be released. We know that this is not the case, because the food was being released at regular pre-defined intervals.\nThis can then be compared to different forms of human superstition. Have you or anybody you known ever had a special ritual at home before every game of our favorite football team? =D\nRats and selective association\nThe phenomenon above can be compared to the behavior of rats as studied by Garcia and Koelling in 1966. Imagine rats going for their regular snack. Some of the rats were then induced to feel ill through an injection or radiation. As could be expected these rats then avoided food with similar taste or smell in the future.\nAnother batch of rats was administered a mild electrical shock in the foot. Interestingly, these rats did not show aversion to the food or water, but instead to an audiovisual cue that always happened while they were eating or drinking.\nThis experiment is widely known as one of the first proofs of the so-called Selective Association Effect. This is related to the concept of biological constraints disccused by students of Skinner. Apparently some animals naturally resist certain types of conditioning, as if they had some kind of built in prior knowledge that some types of relationships could not causal.\nInductive bias\nThis takes us to the concept of inductive bias, which can be described as the set of assumptions or prior knowledge that biases learning by setting restrictions or constraints to the learning process.\nIn our example, the rats seem to be biased towards detecting certain types of patterns between taste or smell and their health, while ignoring other types of seemingly correlated events.\nThis is a well known concept in machine learning. We often talk about models that have high bias or high variance. The second type of models tend to be more complex and are more flexible in the type of functions they can model. But this often makes them more difficult to interpret or prone to overfitting (they memorize the training data, which in this case can be compared to finding superstitious patterns that only apply to that particular set of data).\nBy restricting the types of patterns we are looking for we can often make the learning process easier and also extract valuable insights from the trained model. Linear regression is a great example with well-known assumptions and very powerful applications.\nDeductive vs Inductive reasoning\nJust as a refresher, we can think about deductive and inductive reasoning as taking to different routes (often described as top-down or bottom-up approaches).\nOn one hand (deduction) we start with general theories about how things should work, we develop a hypothesis that we can then confirm through experiments and specific observations.\nDeductive reasoning: - Theory -&gt; Hypothesis -&gt; Observations -&gt; Confirmation\nOn the other hand, we might start with specific observations which we then use to try to discover a pattern in those observations. These patterns that we discover can then lead us to a more generalized understanding of the world.\nInductive reasoning: - Observations -&gt; Pattern -&gt; Tentative Hypothesis -&gt; Theory"
  },
  {
    "objectID": "posts/2021-03-09-computational-learning-theory/2021-03-09-computational-learning-theory.html#statistical-learning-theory",
    "href": "posts/2021-03-09-computational-learning-theory/2021-03-09-computational-learning-theory.html#statistical-learning-theory",
    "title": "Computational Learning Theory - Notes",
    "section": "Statistical Learning Theory",
    "text": "Statistical Learning Theory\nIn statistics it is common to to have well-defined assumptions about the distribution of our data (e.g. Gaussians). In SLT we have no or very general assumptions."
  },
  {
    "objectID": "posts/2021-03-09-computational-learning-theory/2021-03-09-computational-learning-theory.html#is-all-learning-equal",
    "href": "posts/2021-03-09-computational-learning-theory/2021-03-09-computational-learning-theory.html#is-all-learning-equal",
    "title": "Computational Learning Theory - Notes",
    "section": "Is all learning equal?",
    "text": "Is all learning equal?\nIntuitively it would seem that there are different ways of learning. More formally, we can separate learning by different levels:\n\nReproductive learning\n\nIt could be argued that this first level is not learning at all.\nBasically, imagine a class where students are allowed to to take all of their notes to class. It would be possible for a student to create a table with all the information he needs without interiorizing the concepts. Once the exam starts he simply looks up the answers to his questions in the table. So he basically reproduces the information.\nThe negative side is that we need to store all of the relevant information beforehand. This can in many cases be very difficult or even impossible.\n\nRule-based learning\n\nThis level of learning can be thought of as encoding the knowledge of experts. Imagine a medical application created to automatically diagnose different types of diseases. One way to do this would be to get input from a group of doctors and create a flow-chart with nodes for every single decision that could be made.\nNow we don’t need to store the raw data or the observations with their corresponding labels as we would do in reproductive learning. Instead we keep all of these rules that can lead us to an answer.\nThe problem with this approach is that it is also very difficult or even impossible to encode every single use case and the rules are often very brittle.\n\nCreative learning\n\nHere past experience is combined in different ways to solve new problems. This can often be a much more powerful approach as we are not limited to only reproducing past observations or following rigid rules.\nThe main issue here is that it can be quite difficult to explain why a decision has been made.\n\n“If the true classifier is a halfspace, then we should be able to find a very precise separation line with only a few random examples.”\n\n1-nearest neighbor algorithm\nIn this extreme example we store all observations and their lables. Any new lable receives the label of the closest point. Two main conclusions we notice are:\n\nThis algorithm will always classify all training samples correctly.\nThis algorithm will also be able to approximate any smooth function, even where halfspace classifiers perform poorly.\n\n\n\nCode\n\ndef true_classifier(point) :\n    return int(point[0] &gt;= 0)\n\n\ndef nearest_neighbor(train_set, test_point):\n    closest_dist = float('inf')\n    closest = -1\n\n    for features, label in train_set:\n        dist = sum([(p2-p1)**2 for p1,p2 in list(zip(features, test_point))])\n        if dist &lt; closest_dist:\n            closest_dist = dist\n            closest = label\n\n    label = closest\n    return label\n\n\ndef error_probability(train_set) :\n    mistakes = 0\n    no_test_points = 2000\n    for i in range(0,no_test_points):\n        point = (2*i/no_test_points - 1,)\n        if true_classifier(point) != nearest_neighbor(train_set, point) :\n            mistakes += 1\n    return mistakes/no_test_points\n\ntrain_inputs = [-1.0, -0.1, 0.1]\nnew_input = -0.0001\n#-0.0010000000000000009\n\nS = [((x_val,), true_classifier((x_val,))) for x_val in train_inputs]\nerror_S = error_probability(S)\nnew_point = (new_input,)\nS.append( (new_point, true_classifier(new_point)) )\n\nprint(error_S, error_probability(S))\nassert error_S &lt; error_probability(S)\n\n\n0.0005 0.025\n\n\n\n\nCode\n\n\n\n[-1, 0]"
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html",
    "title": "Book: Prediction Machines",
    "section": "",
    "text": "Authors: Ajay Agrawal, Joshua Gans, Avi Goldfarb\nPurchase on: Amazon"
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#placeholder",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#placeholder",
    "title": "Book: Prediction Machines",
    "section": "Placeholder",
    "text": "Placeholder\n\n“Today, business creates value through innovation, the product of human creativity. When creativity replaces muscle power and knowledge manipulation as key factors of economic production, we will witness a creativity revolution, moving one step beyond the knowledge revolution described by management guru Peter Drucker.” - Ming Zeng\n\n\n\n\n\n\n\nNote\n\n\n\nFor more about this very interesting book by Ming Zeng, see my notes on the book “Smart Business”"
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#introduction",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#introduction",
    "title": "Book: Prediction Machines",
    "section": "Introduction",
    "text": "Introduction\nAs economists, the authors claim that it is part of their job to strip away the hype around important technological changes to identify their true value. According to them, AI is a prediction technology, not actual intelligence, and predictions are inputs to decision making.\nFor example, Alexa doesn’t “know” the capital of Delaware, but is able to predict that, when asked such a question, people are looking for a specific response: “Dover.”\nAnother way of putting this is that AI reduces the cost of prediction.\nCreative Destruction Labs (CDL) leverages this insight in such a way that each startup they work with focus on exploiting the benefits of better prediction For instance, Deep Genomics tries to improve the practice of medicine by predicting what will happen in a cell when DNA is altered, and Chisel improves the practice of law by predicting which parts of a document to redact.\nEconomics provides a perfect framework for understanding the trade-offs underlying any decision and the role of artificial intelligence. While many are still trying to grasp AI, the economic principles and implications of changes to cost are clearly defined.\nIt is not the purpose of this book to describe the best strategy for any company, the emphasis is on trade-offs. For example, more data usually means less privacy, more speed means less accuracy, and more autonomy means less control. It is up to the decision-makers to use the structure given in this book to analyze these trade-offs in order to make their decisions.\nCheap changes everything\nAt its core, this book is about strategic thinking using economic principles. It starts by giving past examples of past technological innovations seen as the fall in price of something:\n\nThe rise of the internet was a drop in the cost of distribution, communication, and search.\nGoogle made search cheap.\nComputers made arithmetic cheap.\n\nThe consequences for these changes in price was that substitutes like the Yellow Pages in search lost value while an increase in search (due to a lower price) meant that certain companies that relied on others finding them prospered.\nIn the case of arithmetic, a reduction in price also means increased demand in new areas were arithmetic was not traditionally used. For example, photography used to be mainly chemistry and then became highly digital.\nAs mentioned earlier, the authors view AI as prediction technology. Prediction is the process of filling in missing information. Prediction takes information you have, often called “data,” and uses it to generate information you don’t have.\nJust like with arithmetic, we can then expect to see problems fro other domains being transformed into prediction problems. A clear example of this is transportation.\nTraditionally, people tried to program autonomous vehicles using conditional logic. This system was very limited and brittle because it is practically impossible for humans to program rules for all the scenarios needed. A breakthrough came when this problem was translated into a prediction problem. At any given moment, what would a human do?\nApart from changes in demand and impact on substitutes, economic theory also points us toward complements. We would expect complements to have higher value.\nA practical example of this would be that if the cost of prediction drops, then the value of data collection technology should increase (like Israeli startup Mobileye in the case of autonomous vehicles, which was bought by Intel for more than $15 billion).\n\nThe drop in the cost of prediction will impact the value of other things, increasing the value of complements (data, judgment, and action) and diminishing the value of substitutes (human prediction).\n\n\n\n\n\n\n\nNote\n\n\n\nThis reminded me about a comment in the book A more beautiful question where the author argues that in today’s world information and answers have become commodities. This drop in the cost of accessing information has increased the value of asking good questions, which could be a key component of good judgement. For more about the value of questions, see my notes on the book “A more beautiful question”"
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-one-prediction",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-one-prediction",
    "title": "Book: Prediction Machines",
    "section": "Part One: Prediction",
    "text": "Part One: Prediction\nWhy it’s called intelligence\nThe first few chapters explore fundamental concepts like machine learning and how it is different to traditional statistics and algorithms based on if-then conditional rules.\nManual coding of rules doesn’t work well in very complex environments. Effective automatic prediction puts programming upside-down such that we don’t have to write the whole program. Instead, we train a model that becomes the program we use for prediction and the improvements in performance are often transformational.\nData is the new oil\nOne of the main trade-offs when making strategic decisions about AI is connected to data and, more specifically, data acquisition.\nMachine learning models depend on data for training. as a general rule of thumb, more and better data usually improves performance.\n\nIn economic terms, data is a key complement to prediction. It becomes more valuable as prediction becomes cheaper.\n\nWhen considering prediction algorithms to solve a problem, it becomes important to consider what degree of data freshness might be needed, what type of data, how much data, and so on. For example, collecting data often, such as multiple times every hour, tends to be much more expensive than collecting data once a year.\nSo how do we answer these questions? Usually we find guidance by thinking about the prediction problem we are working on. If we need a model that is 99% accurate for it to be useful we’ll usually need much more data than if we only need to reach a 70% accuracy. There is a set of tools we can use for this called “power calculations”.\nBusiness leaders also need to understand if data has increasing or diminishing returns at scale. Generally, if we have a lot of data then a few more data points would not add much value (diminishing returns), but in problems with many edge cases like recommendation systems there might be increasing value as we get access to data points that competitors will have a tough time obtaining.\nThe new division of labor\nStrictly speaking, we use different types of resources to complete tasks or solve problems. To make effective strategic decisions we need to understand what tasks should be assigned to humans and which can be assigned to machines.\nFor example, psychologists Daniel Kahneman and Amos Tversky discovered with their Prospect Theory that humans are not good utility optimzers, we usually give too much weight to short-term impact and more on losses than gains.\nFraming of information can lead to significantly different actions. When considering a surgery, Kahneman and Tversky found that 84% of physicians would go with surgery if they were told that “the one-month survival rate is 90 percent” compared to only 50% when they were told that “there is a 10 percent mortality in the first month”.\nUnfortunately, as we can see in the experiment above, we are systematically biased and rely on multiple heuristics even when we are aware that they exist. Statistical thinking does not come naturally to us, machines would not change their behavior in this way.\nHumans and machines are also well suited for different types of problems:\n\nKnown knowns. Wwe have rich data and machine prediction can work well.\nKnown unknowns. We know that we don’t have much data and this will impact performance of predictive models while humans are sometimes very good at predicting with limited data.\nUnknown unknowns. When something has ever happened before, both humans and machines tend to be bad at making predictions.\nUnknown knowns. Here the authors point out that there are times when prediction machines give us the wrong answers with a very high level of confidence. This usually happens when the machine does not understand the data-generating process. A common source for this is the presence of confounder variables, such that a naive prediction might suggest that increasing the price would lead to more rooms sold just because both of these events tend to happen together during tourist season.\n\nStill, sometimes the best performance is obtained when humans and machines work together. This is because humans and machines tend to be good at different aspects of a prediction. For example, humans might be better at reducing false positives while the prediction model might be more suited for reducing false negatives.\nThe book presents an example of this when Harvard/MIT team of AI researchers won a contest in 2016 to detect breast cancer. Their deep learning algorithm had an accuracy of 92.5 percent and human pathologists were right 96.6 of the time. Combining their predictions, accuracy increased to 99.5%.\nAn important question for business leaders is how to combine human and machine predictions. The book cites a randomized controlled trial by Daniel Paravisini and Antoinette Schoar where a committee in a bank reviewing loan applicants were given the machine prediction before or after presenting their own assessment.\nThey found that both ways of working improved performance of their decisions, but their was an even higher improvement when the prediction was served in advance. This option empowered low-level managers with information to make more accurate decisions and needed less help from their superiors.\nPresenting the score after the assessment gave high-level managers a tool to monitor the low-level managers and evaluate their decisions, which gave them an incentive to work harder and ensure that they were making high quality decisions.\nA very effective way of combining predictions could also be through prediction by exception such that the machine automatically serves predictions for common events, but calls for human assistance when a rare event is presented and the model has low confidence in the predicted value."
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-2-decision-making",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-2-decision-making",
    "title": "Book: Prediction Machines",
    "section": "Part 2: Decision making",
    "text": "Part 2: Decision making\nUnpacking decisions\nDecision making is a complex process and could be defined in multiple ways. The authors decide to split this process into a set of main components:\n\nInputs (data) used to make the decision\nPrediction, as practically all real life decisions are made under uncertainty. As mentioned earlier, in this book prediction is defined as “the process of filling in missing information”.\nJudgement, defined in the book as “the process of determining the reward to a particular action in a particular environment”.\nAction. This is context-specific and generally produces an outcome with an associated reward or cost.\n\nIn other words, under this model, a decision maker would take into account certain information and apply judgement to a prediction so that an action can be chosen. Note that doing nothing and maintaining the status quo would also be considered an action.\nIt is important to make this distinction because when humans make decisions we usually perform prediction and judgement together and by understanding the different components we can apply the economic framework mentioned earlier. This means that we could take data, judgement and actions as complements to prediction. The value of these complements increases as the cost of prediction decreases.\nWe can also see machine prediction and human prediction as substitutes. This means that the value of human prediction falls as high quality machine prediction becomes cheap.\nThis has very powerful consequences. For example, when the cost of prediction is high we might often fall back to a default rule. So, if it is hard to predict who has been infected by a very contagious virus, we might rely on the hard rule of lock-down for everyone. As the cost of prediction falls, we can use it more often (demand increases) for more granular decisions compared to before. In the example above, if it is easy and cheap to identify who has been infected then we can ask only them to stay at home while everyone who is healthy and not contagious can continue life as usual.\nIf we take this a step further, we can even start to identify areas in business where a high cost of prediction has led us to a path of “satisficing”. One example of this is the existence of lounges at airports. They exist because it is hard to predict how long it will take to get to the airport and through to the gate. If the cost of predicting traffic, dangerous threats at the airport, and possible delays drop, then we could leave just in time to get to the gate and lounges would not be needed.\nCheap prediction makes judgement even more important because it allows us to define what our objective actually is and what value/reward we assign to each possible outcome of an action. In the case of algorithms, applying judgement can be seen as choosing the “reward function”.\nThe value of judgement\nChoosing the reward function is a human process as we currently decide what is considered valuable or not. It is a key piece of decision making and as long as we are needed for this, humans still play a key role in the use of AI.\nIt is easy to confuse the use of AI in domains such as credit worthiness as simply prediction. Someone within the business has to make the decision of how much risk they are willing to carry at specific interest rates and this leads to completely different business models. This would be the example of a high-end platinum card vs an entry-level card for students.\nOnce this has been defined, judgement can be baked into software (like a threshold applied to the prediction made by a model) and the full process can be automated.\nJudgement is usually expensive in time and effort, especially when the realm of possible outcomes is large and there is a high level of uncertainty. Uncertainty increases the cost of judgement because we don’t only need to think about the value of a possible outcome but also the cost of acting on a wrong prediction.\nPredicting judgement\nOf course, earlier it was mentioned that a lower cost of prediction would allow us to transform problems from other domains into prediction problems. So, wouldn’t it be possible for machines to learn to apply judgement by converting it into a prediction of “What would a human do in this situation?”\nThe authors remind us about the types of problems where machines are well suited or not. Machines are bad at predicting rare events due to the lack of data, and this is usually the case when we need to apply judgement."
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-3-tools",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-3-tools",
    "title": "Book: Prediction Machines",
    "section": "Part 3: Tools",
    "text": "Part 3: Tools\nDeconstructing workflows\nDuring the IT revolution, when thinking about where to use computers, many businesses could simply look for places where they were already doing a lot of manual computations and replace humans with computers.\nUnfortunately, for many other companies it wasn’t as simple. Michael Hammer and James Champy published the book Reengineering the Corporation in 1993. They argued that for general-purpose technology like computers it is important to go back to the foundation and think about the true objective of the business. With this in mind they can then review their workflows to identify which tasks were truly needed to achieve their objective and evaluate if computers had a role in those tasks.\nAI is also a general-purpose technology, so this book proposes that companies evaluating how to implement AI should break down the tasks in their workflows and identify the ones truly needed to achieve their objectives. Then they can estimate the ROI of either building or buying AI to leverage machine predictions for each task, order the tasks in terms of ROI and then start implementing from the top.\nDecomposing decisions\nHere the authors revisit the components of a decision and include additional components that are necessary for building automated prediction models. This makes up what they call the “AI canvas” used to understand the potential value of machine predictions:\n\nAction: What are you trying to do? A company like Atomwise wants to test molecules to help cure or prevent disease.\nPrediction: What do you need to know to make the decision? Atomwise predicts binding affinities of potential molecules and proteins.\nJudgement: How do you value different outcomes and errors? Atomwise and its customers decide the relative importance of a cure compare to the cost of potential side effects.\nOutcome: What are your metrics for task success? For Atomwise, did the test lead to a new drug?\nInput: What data do you need to run the predictive algorithm? Atomwise uses data on the characteristics of the disease proteins.\nTraining: What data do you need to train the predictive algorithm? Atomwise employs data on the binding affinity of molecules and proteins, along with molecule and protein characteristics.\nFeedback: How can you use the outcomes to improve the algorithm to improve future predictions?\n\nThe canvas is valuable in the sense that it allows us to remember the different components and forces us to clearly describe each component. For example, when evaluating the trade-offs between cure and side effects, we are applying judgement and it becomes explicitly defined in the canvas. Also, knowing what we want to achieve and how helps us to identify what data we would need.\nA seemingly simple thing such as identifying what we want to predict can often lead us to a more existential discussion around the question “What is our real objective?”\nWhen human prediction and judgement are mixed there is more space for ambiguity, but when prediction is decoupled it forces us to be specific.\nSome companies have to go back and review their mission statement as a first step in their AI strategy, and more often need to be specific in their objectives throughout the company.\n\n\n\n\n\n\nNote\n\n\n\nCassie Kozyrkov, Chief Decision Scientist at Google, has a great post on operationalization (“creation of measurable proxies for rigorously investigating fuzzy concepts”) here.\nOperationalization is one way in which we can convert ambiguous objectives into something specific and measurable.\n\n\nJob redesign\nWhen computers made arithmetic cheap, spreadsheets didn’t become a threat to bookkeepers because they were the ones that made the computations manually before and now became the best suited to ask the right questions of the spreadsheets. In other words, they not replaced but rather empowered and augmented.\nThe implementation of AI tools generates four implications for jobs:\n\nJob augmentation, as in the example of spreadsheets and bookkeepers.\nJob contraction, as in fulfillment centers.\nReconstitution of jobs, with some tasks added and others taken away, as with radiologists.\nShift the emphasis on the specific skills required for a particular job as with bookkeepers"
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-4",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-4",
    "title": "Book: Prediction Machines",
    "section": "Part 4:",
    "text": "Part 4:"
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#chapter-15-ai-in-the-c-suite",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#chapter-15-ai-in-the-c-suite",
    "title": "Book: Prediction Machines",
    "section": "Chapter 15: AI in the C-suite",
    "text": "Chapter 15: AI in the C-suite\nC-suite leadership must not fully delegate AI strategy to their IT department because powerful AI tools may go beyond enhancing the productivity of tasks performed in the service of executing against the organization’s strategy and instead lead to changing the strategy itself.\nAI can lead to strategic change if three factors are present:\n\nthere is a core trade-off in the business model (e.g., shop-then-ship versus ship-then-shop);\nthe trade-off is influenced by uncertainty (e.g., higher sales from ship-then-shop are outweighed by higher costs from returned items due to uncertainty about what customers will buy);\nan AI tool that reduces uncertainty tips the scales of the trade-off so that the optimal strategy changes from one side of the trade to the other (e.g., an AI that reduces uncertainty by predicting what a customer will buy tips the scale such that the returns from a ship-then-shop model outweigh those from the traditional model).\n\nPrediction machines will increase the value of complements, including judgment, actions, and data. The increasing value of judgment may lead to changes in organizational hierarchy.\nReturning to the simple economics that underlies all the arguments in this book, prediction and judgment are complements; as the use of prediction increases, the value of judgment rises. Teams are increasingly bringing in new senior advisers who sometimes may not have firsthand experience playing the game and—true to stereotype—may not be an obvious fit in the jock world of professional sports. However, even nerds recruited into this setting require a deep understanding of the game because using prediction machines in sports management means an increase in the value of people who have the judgment to determine payoffs and, therefore, the judgment to use predictions in decisions.\nBetter prediction now enables the manager to make decisions that are closer to the organization’s objectives: determining the best team rather than the best individual players. To make the most of prediction machines, you need to rethink the reward functions throughout your organization to better align with your true goals."
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#chapter-16-when-ai-transforms-your-business",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#chapter-16-when-ai-transforms-your-business",
    "title": "Book: Prediction Machines",
    "section": "Chapter 16: When AI transforms your business",
    "text": "Chapter 16: When AI transforms your business\nA key strategic choice is determining where your business ends and another business begins—deciding on the boundary of the firm. Uncertainty influences this choice. Because prediction machines reduce uncertainty, they can influence the boundary between your organization and others.\nBy reducing uncertainty, prediction machines increase the ability to write contracts, and thus increase the incentive for companies to contract out both capital equipment and labor that focuses on data, prediction, and action. However, prediction machines decrease the incentive for companies to contract out labor that focuses on judgment. Judgment quality is hard to specify in a contract and difficult to monitor. If judgment could be well specified, then it could be programmed and we wouldn’t need humans to provide it. Since judgment is likely to be the key role for human labor as AI diffuses, in-house employment will rise and contracting out labor will fall.\nAI might enable machines to operate in more complex environments. It expands the number of reliable “ifs,” thus lessening a business’s need to own its own capital equipment, for two reasons. First, more “ifs” means that a business can write contracts to specify what to do if something unusual happens.\nSecond, AI-driven prediction—all the way to predicting consumer satisfaction—would enable companies to more confidently design products up front, thus leading to high consumer satisfaction and performance without the consequent need for extensive mid-model adjustments.\nStudies found that automobile companies that are parts themselves improved faster, but companies that used external providers had higher initial satisfaction due to higher quality of the parts.\nIt is not clear what the impact on outsourcing would be if processes become more complex since better prediction drives more outsourcing, while more complexity tends to reduce it. Which of these factors might dominate is hard to say at this stage. We can say that, while newly feasible complex processes might be done in house, many of the simpler processes previously completed in house will be outsourced.\nThe direct implication of this line of economic logic is that AI will shift HR management toward the relational and away from the transactional. The reason is twofold. First, human judgment, where it is valuable, is utilized because it is difficult to program such judgment into a machine. The rewards are either unstable or unknown, or require human experience to implement. Second, to the extent that human judgment becomes more important when machine predictions proliferate, such judgment necessarily involves subjective means of performance evaluation. If objective means are available, chances are that a machine could make such judgment without the need for any HR management. Thus, humans are critical to decision making where the goals are subjective. For that reason, the management of such people will likely be more relational.\nAnother critical strategic issue is the ownership and control of data. For AI startups, owning the data that allows them to learn is particularly crucial. Otherwise, they will be unable to improve their product over time.\nMany AI leaders, including Google, Facebook, and Microsoft, have built or purchased their own advertising networks so that they can own this valuable data. They decided that owning this data is worth the cost of acquiring it.\nGoogle, Facebook, Microsoft, and a handful of other companies have particularly useful data on consumer preferences online. Rather than only sell data, they go a step further to make predictions for advertisers.\nWhether you collect your own data and make predictions or buy them from others depends on the importance of prediction machines to your company. If the prediction machine is an input that you can take off the shelf, then you can treat it like most companies treat energy and purchase it from the market, as long as AI is not core to your strategy. In contrast, if prediction machines are to be the center of your company’s strategy, then you need to control the data to improve the machine, so both the data and the prediction machine must be in house."
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#chapter-17-your-learning-strategy",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#chapter-17-your-learning-strategy",
    "title": "Book: Prediction Machines",
    "section": "Chapter 17: Your learning strategy",
    "text": "Chapter 17: Your learning strategy\nShifting to an AI-first strategy means downgrading the previous top priority. In other words, AI-first is not a buzz word—it represents a real tradeoff. An AI-first strategy places maximizing prediction accuracy as the central goal of the organization, even if that means compromising on other goals such as maximizing revenue, user numbers, or user experience.\nThe economist’s filter knows that any statement of “we will put our attention into X” means a trade-off. Something will always be given up in exchange. AI-first means devoting resources to data collection and learning (a longer-term objective) at the expense of important short-term considerations such as immediate customer experience, revenue, and user numbers.\nThe central strategic dilemma is whether to prioritize that learning or instead shield others from the performance sacrifices that entails.\nThis is the classic “innovator’s dilemma,” (Clay Christensen) whereby established firms do not want to disrupt their existing customer relationships, even if doing so would be better in the long run. The innovator’s dilemma occurs because, when they first appear, innovations might not be good enough to serve the customers of the established companies in an industry, but they may be good enough to provide a new startup with enough customers in some niche area to build a product. Over time, the startup gains experience. Eventually, the startup has learned enough to create a strong product that takes away its larger rival’s customers. By that point, the larger company is too far behind, and the startup eventually dominates. AI requires learning, and startups may be more willing to invest in this learning than their more established rivals.\nAI-enabled products are often inferior at first because it takes time to train a prediction machine to perform as well as a hard-coded device that follows human instructions rather than learning on its own. However, once deployed, an AI can continue to learn and improve, leaving its unintelligent competitors’ products behind. It is tempting for established companies to take a wait-and-see approach, standing on the sidelines and observing the progress in AI applied to their industry. That may work for some companies, but others will find it difficult to catch up once their competitors get ahead in the training and deployment of their AI tools.\nAnother strategic decision concerns timing—when to release AI tools into the wild. AI tools are, initially, trained in house, away from customers. However, they learn faster when they are deployed into commercial use because they are exposed to real operating conditions and often to greater volumes of data. The benefit to deploying earlier is faster learning, and the cost is greater risk."
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#chapter-18-managing-ai-risk",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#chapter-18-managing-ai-risk",
    "title": "Book: Prediction Machines",
    "section": "Chapter 18: Managing AI risk",
    "text": "Chapter 18: Managing AI risk\nAI carries many types of risk\n\nPredictions from AIs can lead to discrimination.\nAIs are ineffective when data is sparse. This creates quality risk, particularly of the “unknown known” type, in which a prediction is provided with confidence, but is false.\nIncorrect input data can fool prediction machines, leaving their users vulnerable to attack by hackers.\nJust as in biodiversity, the diversity of prediction machines involves a trade-off between individual- and system-level outcomes. Less diversity may benefit individual-level performance, but increase the risk of massive failure.\nPrediction machines can be interrogated, exposing you to intellectual property theft and to attackers who can identify weaknesses.\nFeedback can be manipulated so that prediction machines learn destructive behavior."
  },
  {
    "objectID": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-5-society",
    "href": "posts/2021-09-15-prediction-machines/2021-09-15-prediction-machines.html#part-5-society",
    "title": "Book: Prediction Machines",
    "section": "Part 5: Society",
    "text": "Part 5: Society\nBeyond business\nJobs are one thing. The income they generate is another. Opening up trade often creates competition, and competition causes prices to drop. If the competition is with human labor, then wages fall.\nAs with trade between countries, winners and losers from trade with machines will appear. Jobs will still exist, but some people will have less appealing jobs than they have now. In other words, if you understand the benefits of free trade, then you should appreciate the gains from prediction machines. The key policy question isn’t about whether AI will bring benefits but about how those benefits will be distributed.\nIf the machines’ share of work continues to increase, then workers’ income will fall, while that accruing to the owners of the AI will rise.\nA second trend leading to increased inequality is that technology is often skill-biased. It disproportionately increases the wages of highly educated people and might even decrease the wages of the less educated.\nAI will unambiguously enhance productivity. The problem isn’t wealth creation; it’s distribution. AI might exacerbate the income inequality problem\nThe second trade-off is innovation versus competition\nThe third trade-off is performance versus privacy."
  },
  {
    "objectID": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html",
    "href": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html",
    "title": "A More Beautiful Question",
    "section": "",
    "text": "Author: Warren Burger\nPurchase on: Amazon"
  },
  {
    "objectID": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#introduction",
    "href": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#introduction",
    "title": "A More Beautiful Question",
    "section": "Introduction",
    "text": "Introduction\nThe author’s interest in questioning started when he was interviewing some of the most innovative minds for a series of articles and a book he wrote. One common denominator he found was that they were all very good as asking questions.\nFor many of them, their breakthrough products, solutions or services started with a key question or a series of questions that they asked and then answered.\nInterestingly though, most companies and schools don’t teach or encourage good questioning. It is often seen as a waste of time, rebellion towards authority or as a sign of ignorance. Therefore, obedience and memorization is often favored in these settings.\nAnyone who has been around small children for a while knows that asking questions comes naturally to them. The book quotes a study that claims that the average girl in the UK asks her mother 390 questions per day. Over time children ask less and less questions.\nThe title of the book was borrowed from this quote:\n\n“Always the beautiful answer who asks a more beautiful question” - E. E. Cummings\n\nIt is then worth asking ourselves why questioning is not as common as we could expect. To answer this we have to remember that questions tend to disrupt processes and structures that already exist. Questions also force us to wonder if things could be done differently. So, in a way, encouraging people to ask questions implies giving up power. To allow for more questioning means that the people in charge (e.g. leaders or teachers) need to be willing to give up control.\nAfter a great number of interviews and borrowing from well-known theories in areas like design thinking, the author crated a three-part framework to formulate and tackle big, beautiful questions:\n\nWhy?\nWhat if?\nHow?\n\nThe author also finishes the introduction with his own subjective definition of a beautiful question:\n\n“A beautiful question is an ambitious yet actionable question that can begin to shift the way we perceive or think about something and that might serve as a catalyst to bring about change”."
  },
  {
    "objectID": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-1-the-power-of-inquiry",
    "href": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-1-the-power-of-inquiry",
    "title": "A More Beautiful Question",
    "section": "Chapter 1: The Power of Inquiry",
    "text": "Chapter 1: The Power of Inquiry\n\nIf they can put a man on the moon, why can’t they make a decent foot?\n\nThis chapter starts with the emotional but very powerful story about Van Phillips, who received a prosthetic leg of wood and foam rubber after he lost his leg in a water-skiing accident in the late 1970s.\nPhillips asked “Why can’t a prosthetic leg perform more like a human one?” and “Why can’t it bend and flex, enabling a person to run and jump?”\nExperts in a field can often take this type of questions as challenges to their expertise. For this reason, outsiders are often best positioned to ask questions, while experts are usually very bad at asking questions in their own subject area.\nPhillips decided to try to answer the question himself. Mark Noonan, inventor of the wheeled shovel, has said that if we never do anything about a problem ourselves, then we are not really questioning. We are complaining.\nFast-forwarding several years, Phillips work has impacted the lives of thousands of people and many of us heave seen or heard the story about South Africa’s Oscar Pistorius (aka “the blade runner”), the first double-amputee runner to compete in the Olympics. He ran with a pair of carbon-fiber prosthetic legs known as Cheetahs, created by Van Phillips.\nWhy do we ask questions? Well, one one main reason is when we become aware of something that we don’t know. That’s why good questioners tend to be aware and comfortable with their own ignorance.\nQuestioning can also be a way of activating divergent thinking, which usually happens in the creative right hemisphere of the brain. This would allow us to trigger random association of ideas and our imagination to discover new ideas.\nWe can also leverage different types of questions depending on what we need. For example, open questions tend to encourage more creative answers than closed questions, even though these are also important.\nThe tone is also very important. The same question can be asked with a negative or positive tone. The second type of questions usually produces better answers.\nDavid Cooperrider, from Case Western Reserve University, is one of the creators of the appreciative inquiry model. This model assumes that the questions we ask tend to focus our attention in a specific direction. One interesting result of this would be that organizations evolve in the direction of the questions they most persistently and passionately ask.\nFor example, questions like “Why are we falling behind our competitors?” tend to reinforce a culture of finger-pointing while more expansive and optimistic questions encourage collaboration and innovation. The same would be true for our countries, communities and families.\n\n“Forming questions helps us to organize our thinking around what we don’t know” - Stephen Quatrano, The Right Question Institute\n\nIf we borrow from economic theory, we could also say that information has become a commodity and the value of knowledge has been decreasing. With so much information available to us, it becomes very difficult to know which questions to ask. This means that the value of good questions has been rising.\nWe see this same phenomenon with computers, they are extremely efficient at giving us answers we are looking for but they are still not capable of producing valuable questions consistently.\nThe last part of the chapter focuses on the main stages of innovative questioning and the author’s three-part model:\n\nWhy: Confronting, formulating and framing the initial questions that define the problem we have identified. This corresponds to the “why?” moment because we are trying to understand why the problem exists, why it creates an opportunity/need/pain and for whom. We also want to understand why others have not solved it and why it should be important to us. These “why” questions often come unexpectedly in our daily lives.\nWhat if: We take the understanding we have gained in the previous stage and formulate hypotheses to solve the problem. This is the first step in moving from questions to actions. The author also describes the concepts of contextual inquiry and connective inquiry. We use the first type when we are trying to get more context about the problem we are interested in. Connective inquiry is the kind of questions we use when we start to combine knowledge from other fields or domains with the problem at hand. This produces questions like “What if a prosthetic leg could have the same strength and flexibility as a springboard so that the person could jump?”. “Often the worst thing we can do with a difficult question is to try to answer it too quickly”.\nHow: Decide on a specific solution, build prototypes and/or construct a plan. This is where most of the action happens and this type of questions tend to be much more practical (e.g. “How do I test this idea?” or “How can I get this to work?”)."
  },
  {
    "objectID": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-2-why-we-stop-questioning",
    "href": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-2-why-we-stop-questioning",
    "title": "A More Beautiful Question",
    "section": "Chapter 2: Why we stop questioning",
    "text": "Chapter 2: Why we stop questioning\nThis chapter starts with the apparently never-ending ability of small children to ask questions. Unfortunately, studies show that as they grow up the number of questions that they ask falls drastically and by middle school questioning has practically stopped.\nOne interesting finding is that one main reason children ask why over and over again is because they feel their question has not been answered. In other words, it’s their way of saying “you are not hearing me, you still don’t understand what I’m asking”.\nAs children move into more standardized learning, it seems like we are robbing them of the opportunity to explore and discover questions on their own. Many schools and teachers are tasked with filling up our heads with as many answers as possible based on a list of topics that have to be taught. This leaves very little time for questions that deviate from the topics that have to be covered. Children are forced to sit still in class and memorize as much as possible.\nThis raises the question “what if our schools could train students to be better life-long learners and better adapters to change by enabling them to be better questioners?”\nThis chapter includes the story of Deborah Meier who started applying experimental approaches to learning in the 60s and 70s in Harlem. Her approach was based on questions, but many viewed this as undisciplined and without structure. Meier’s response to this was that children are easier to control when they have the freedom to focus on what they were interested in.\nFor a decade, when the average dropout rate of the city was 40-60%, only 1% of Meier’s students failed to finish secondary school.\n\nIf you can’t imagine that you could be wrong, what’s the point of democracy? And if you can’t imagine how or why others think differently, then how could you tolerate democracy?\n\nIt is not only children that benefit from better questions. The book follows multiple experiences by Rothstein and Santana from the Right Question Institute. For example, they found that many parents refused to go to school meetings. They wondered “Why?” and were told by the parents that they didn’t go because they didn’t know what questions to ask.\nThey decided to train the parents with various questioning techniques and soon discovered that the parents were using these techniques in other contexts as well (in th emergency room, when discussing with a landlord, etc.).\nRothstein and Santana designed a question formulation program for K-12 classrooms with the following steps:\n\nTeachers design a Question Focus (e.g. Torture can be justified)\nStudents produce questions without the teacher’s help, no answers allowed.\nStudents improve their questions by, for example, opening closed questions and closing open questions.\nStudents prioritize their questions. Usually a top three among all students.\nStudents and teachers decide on next steps, for acting on prioritized questions.\nStudents reflect on what they have learned."
  },
  {
    "objectID": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-3-the-why-what-if-and-how-of-innovative-questioning",
    "href": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-3-the-why-what-if-and-how-of-innovative-questioning",
    "title": "A More Beautiful Question",
    "section": "Chapter 3: The Why, What if, and How of Innovative Questioning",
    "text": "Chapter 3: The Why, What if, and How of Innovative Questioning\nThis chapter dives deep into multiple examples of innovation though questions in companies like Polaroid, Airbnb and Pandora.\nThe Polaroid Tale is a great example of questions driving innovation. Edwin Land, who would become co-founder of the Polaroid Corporation, was taking pictures of his daughter Jennifer one day during a vacation and she asked why they couldn’t see the pictures without having to wait.\nAs a scientist, Land was hooked by this question and immediately started exploring questions like “What if you could somehow have a darkroom inside a camera?”.\n\nIf What if is about imagining and How is about doing, the initial Why stage has to do with seeing and understanding.\n\nWhy?\nHow do we ask powerful Why questions? The author proposes:\n\nStep back\nNotice what others miss\nChallenge assumptions (including our own)\nGain a deeper understanding through contextual inquiry\nQuestion the questions we are asking. Questions also have assumptions.\nTake ownership of a particular question\n\n\nPart of the value in asking naïve questions is that it forces people to explain things simply, which can help bring clarity to an otherwise complex issue - Paul Bennett\n\nAt this point, the value of questioning seems obvious, but actually asking the questions is hard. It can be challenging and even uncomfortable. Paul Bottino, director of Harvard University’s student-innovator program, says that the only way to get more comfortable questioning expert assumptions of others is to do it repeatedly and over time.\nWHat if?\nThe What if stage where anything is possible. For Pandora, an example could be “What if a radio station could know what songs you would like before you know?\nHere it is worth noting that a creative act does not necessarily mean creating something from scratch, but could also be a smart new recombination of things that already exist.\nResearch shows, contrary to what our fast-paced lives would demand, that we should “live with” challenging questions for a time instead of answering them right away. This allows our brain to find fresh insights and possibilities. States of inattention, when we are relaxed or distracted, seem to often produce more novel ideas or solutions. Especially when we move back and forth between attention and inattention.\nHow?\nFinally, How questions allow us to converge around what is or is not doable. The danger here is that we often hold back our ideas until they are polished and perfect. Children tend to be quicker and fearless when moving from What if to How.\nThe author describes an interesting experiment where Harvard MBA grad students competed with kindergarten children using spaghetti and a marshmallow to create the tallest tower. The kindergarten children won easily by quickly jumping into a hands-on try and learn loop, while the MBA graduates spent a lot of time deciding who would be the leader and then planning analytically how to build the tallest tower.\nThe Lean Startup methodology by Eric Ries follows a similar fast-paced learning cycle through focused experimentation.\nFollowing this idea, we are also encouraged to share beautiful questions with others early instead of hiding them until we have a solution. We might find help from others so that we find a higher quality solution faster."
  },
  {
    "objectID": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-4-questioning-in-business",
    "href": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-4-questioning-in-business",
    "title": "A More Beautiful Question",
    "section": "Chapter 4: Questioning in Business",
    "text": "Chapter 4: Questioning in Business\nThe Innovator’s Dilemma by Clayton Christensen was born out of a question:\n\nWhy are the smartest people in the world having this problem?\n\nChristensen had noticed that established and market-leading companies were consistently being outplayed by new entrants with simpler and more affordable products. Even more interesting was the fact that managers and leaders in the established firms seemed to be doing everything right compared to what was being taught in business schools.\nThis led Christensen to discover a dilemma faced by these companies:\n\nShould we make better products that we can sell for higher profits to our best customers - or make worse products that none of our customers would buy, and that would ruin our margins?\n\nGoing into the low-end often doesn’t make sense for the market leaders, and this opens up space for new competitors. The question then is why these business leaders weren’t capable of identifying this dilemma themselves.\nThe author claims that it is because of a lack of questioning in business, and there are multiple reasons for this. For example, the push for short-term results often leaves little room for questioning and focus on efficiency generally leads managers away from more expansive questions.\nGreat part of of the chapter goes into examples of important questions for business leaders to ask. Among these, the purpose of the business is one of the most important and periodic questioning might reveal a need to update the purpose.\n\n\n\n\n\n\nNote\n\n\n\nThis reminded me of Ming Zeng comparing the vision of a company to the objective function of an algorithm. It sets the direction for how the company evolves, and might need to be re-calibrated after validating the vision in reality through continuous experiments. For more on this, see my notes on the book “Smart Business”\n\n\nThe value of experiments is highlighted here as well. Borrowing from Eric Ries (author of The Lean Startup), we are told that emphasis should be on “what will we learn?” instead of “what will we build/do?”\nAn alternative to brainstorming is question-storming. It tends to be much easier to come up with questions than ideas. It is also easier to identify the best questions than the best ideas.\nThis does not mean that we can go to the other extreme of only asking questions, it is important to also know when to stop and take action. We don’t want to get stuck in nonproductive or uninformed questions either."
  },
  {
    "objectID": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-5-questioning-for-life",
    "href": "posts/2021-04-27-a-more-beautiful-question/2021-04-27-a-more-beautiful-question.html#chapter-5-questioning-for-life",
    "title": "A More Beautiful Question",
    "section": "Chapter 5: Questioning for life",
    "text": "Chapter 5: Questioning for life\nThis chapter becomes more personal. For example, it brings up one of Daniel Pink’s favorite questions: “what is your sentence?”. This comes from the idea that the life of someone with a clear purpose could be summed up in a single sentence (e.g. “He raised four kids who became happy, healthy adults”).\nFrequent questioning might also help us avoid unfulfilling predetermined paths that we take just by living in a type of “autopilot” state.\nBut questioning ourselves is hard. It might help to remember that “not knowing” the answers to our questions is ok, and the more we question the easier it gets.\nSelf-questioning also tends to lead us down a negative spiral of regret and lack of confidence. For this reason, it can be useful to use appreciative inquiry or strength-based questioning. The idea is that questions focusing on our strengths tend to produce better outcomes than questions focused on our weaknesses.\nAnother interesting question about personal life was asked by filmmaker Roko Belic: “Why is it that people who have so little and have suffered so much seem to be happier than other people who are more fortunate?”.\nAs a filmmaker, Belic also asked a follow-up question:\n\nIf being a beautiful, talented, wealthy movie star doesn’t make you happy, then what does?\n\nTraveling the world searching for material for a film on happiness, he noted that community and connectedness was a common pattern for happy people. They enjoyed being with the people they love, they laugh and have a strong connection to the people around them.\nAnother powerful question for those looking for happiness is “What did I love doing as a child?”, chances are we would still love to do them today.\nTo convert our questions into actions, the author takes us back to the theme on experimentation.\n\n“We learn who we are - in practice, not in theory - by testing reality” - Herminia Ibarra\n\nFor example, we can look for temporary assignments, extended vacations, MVP versions for an idea we have, etc.\nQuestions about life don’t necessarily have to focus on our own lives. Another example in the book is that of youth pastor Joel Van Dyke who found the quote by E. E. Cummings about beautiful questions. He decided to ask youth, including gang leaders, in his neighborhood “how would you reach yourself?” instead of assuming that he knew what they needed. They told him that they would like to play handball but were not allowed in the local facilities. His church started sponsoring 4 tournaments a year and this opened up a channel to share the message with the youth.\nQuestions also help us understand the world from the perspective of those who hold opposing views in a way that is less confrontational and defensive. We might even be able to agree on a question even if we don’t agree on the answer.\nThe final pages of the book encourage us to look for beautiful questions and stay with it if we find one, it will probably be hard to answer. It doesn’t only have to be one beautiful question, some cycle through different beautiful questions every certain amount of years. but it is good to focus on just one at a time."
  },
  {
    "objectID": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html",
    "href": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html",
    "title": "Smart Business",
    "section": "",
    "text": "Author: Ming Zeng\nPurchase on: Amazon"
  },
  {
    "objectID": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html#introduction-why-you-need-to-know-about-alibaba",
    "href": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html#introduction-why-you-need-to-know-about-alibaba",
    "title": "Smart Business",
    "section": "Introduction: Why you need to know about Alibaba",
    "text": "Introduction: Why you need to know about Alibaba\nThe book starts with a series of impressive examples experienced during Singles Day (November 11th) 2017, now one of the largest shopping events in the world.\nThat year Alibaba set a world record for most payment transactions during the festival, Alipay processed 256.000 payment transactions per second, it took 28 seconds to reach 1 billion RMB in sales, and the first package was delivered only 12 minutes after the midnight start of the event.\nIn comparison, the author explains that as of August 2017, the stated capacity of Visa was 65.000 payments per second globally.\n\n“Alibaba is not China’s version of Amazon”\n\nAlibaba has historically often been described as “the Amazon of China” (I have personally used this description when talking to others before I lived in China for a semester).\nThe author suggests that we should think of Alibaba as doing what Amazon, eBay, PayPal, Google, FedEx, the wholesalers and a portion of the manufacturers in the United States do.\nBorrowing a quote from Jack Ma (“e-commerce is the main course in China but only dessert in the US”), we are led to understand that China’s weak and undeveloped infrastructure a few decades ago allowed the country to leapfrog ahead of other countries. Without the weight of legacy infrastructure and high switching costs seen in countries like the US, China was able to develop internet-native retailing, payment and logistics ecosystems.\nThis is not unique to China, other countries with undeveloped infrastructures have started to follow this example. The author claimed that Alipay is becoming the standard for mobile payments across Asia and that Alibaba’s e-commerce model is expanding rapidly in India.\nOne of the major drivers of the disruptive ecosystems in China, is the use of cutting-edge technology like cloud computing and machine learning.\nThe author’s definition of smart business:\n\nI call this strategy of embracing new technology to connect all your players and redesign industries smart business.\n\nFor example, coordinating business activity across an extremely large number of interconnected players is impossible without automating a lot of actions and decisions. This is made possible using tools like machine learning.\n\n\n\n\n\n\nNote\n\n\n\nFor more on the role of machine learning in predictions and decision-making, see my notes on the book “Prediction machines”"
  },
  {
    "objectID": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html#part-one---alibaba-the-emergence-of-a-smart-business",
    "href": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html#part-one---alibaba-the-emergence-of-a-smart-business",
    "title": "Smart Business",
    "section": "Part one - Alibaba: The emergence of a Smart Business",
    "text": "Part one - Alibaba: The emergence of a Smart Business\n\nThe new forces of value creation\nThe mission of Alibaba is “To make it easy to do business anywhere”. This has guided the company in creating the technology infrastructure to allow merchants and businesses to engage with their customers.\nThe essence of smart business:\n\nNetwork Coordination + Data Intelligence = Smart Business\n\nComplicated business activity, which was previously locked into rigid and vertically integrated structures, can now be broken down using networked approaches thanks to reduced transaction costs enabled by technology.\nBusinesses can coordinate automatically, which allows for decentralized, scalable and optimized processes.\nAutomatic coordination is usually digital, which makes it possible to collect data and leverage what the author calls data intelligence: “business capability of effectively iterating products and services according to consumer activity and response”.\nChinese companies are better positioned to take advantage of network coordination due to the internet-native infrastructure described above, while companies in the US excel at data intelligence.\nIn this environment, the familiar forces of competition lose importance in favor of new forms of coordination, this means that the ways of creating value are completely transformed.\n\n\nNetwork Coordination\nThe current disruptive nature of China’s logistics ecosystem was born out of disasters and major headaches, such as Singles Day in 2012.\nThe author attributes great part of the rapid evolution of China’s logistics infrastructure to network coordination, such that multiple players learned to coordinate efficiently and at scale leveraging internet platforms and data.\nNetwork coordination in Alibaba was born out of scarcity of resources. For example, they could not start their own delivery company to avoid the country’s slow and outdated postal system. Instead, engineers built standard tools to allow the integration of these services to Alibaba’s platform and encouraged other players to create the services.\nThe focus of the company shifted toward managing this coordination of a large network of players instead of spending most of the time transmitting information vertically between suppliers and customers.\nBusiness networks are formed when multiple players unite to solve a complex commercial problem for a client base. The author provides four building blocks of coordinated networks based on their experience with Taobao:\n\nDirect connection and interaction. This is one of the key factors which helped Taobao beat eBay in China.\nRole evolution. The network needs to develop, and can’t be completely planned. The definitions of participants’ roles need to be fuzzy at first. They are then allowed to evolve and when they solidify they can receive official support. Too rigid definitions can limit the network’s growth.\nInvestment in infrastructure like APIs, search functionality, reputation systems, etc.\nPutting business activities online or business “softwaring”.\n\nOne of the major benefits of the network, enabled by the principles above, is flexibility.\nExamples of network coordination that are easier to relate to in the West are Wikipedia, the open-source movement, etc.\n\n\nData intelligence\nLeveraging data to automate actions and decisions opens up new opportunities and scale.\n\nNo one assigns an Uber car to a rider, and no Taobao associate recommends a dress; the algorithms do it. Although there is an enormous amount of human effort and creativity involved in creating these services, once that effort is done, the business practically runs itself.\n\nAs an example, the author describes the use of data and machine learning in Alibaba to kick-start within Alipay an effective, scalable and profitable SME lending business.\nThree cornerstones data intelligence to operate:\n\nAdaptable products\nDatafication (similar to digitalization but is used by the author to emphasize a greater breadth of types of data)\nMachine learning"
  },
  {
    "objectID": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html#part-two---how-smart-businesses-compete-strategic-principles",
    "href": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html#part-two---how-smart-businesses-compete-strategic-principles",
    "title": "Smart Business",
    "section": "Part two - How smart businesses compete: Strategic principles",
    "text": "Part two - How smart businesses compete: Strategic principles\nThis part describes the core principles of smart business, such as “softwaring” workflows to automate decision-making.\nTo make smart business possible it is critical that the business model is re-aligned around customer, the author calls this the consumer-to-business model.\n\nAutomating decisions\nFive steps:\n\nDatafy the physical world. Events and processed need to be encoded so that they can be understood by computers.\nSoftware the business. “Softwaring” is the process of retooling a business, its people and its resources using software so that it can achieve network coordination and data intelligence.\nGet data flowing and introduce APIs.\nRecord data in full\nApply machine learning algorithms\n\nOur understanding of a business activity determines how it gets turned into data and this defines which products and services can be created to solve the business problem.\n\n\nThe Customer-to-Business model\nThis C2B model is in direct contrast to the traditional B2C model. This is because when machine learning drives business decisions through feedback loops based on customer behavior, then the customers are effectively dictating the company’s actions.\nFor this to be possible, companies need to decouple processes so that they are functionally independent but allow them to integrate automatically.\nThis part of the book shows multiple examples of C2B models in China in great detail, such as the “web celebs”: influencers that have learned to leverage the platform together with other players which allow them to compete with large brands.\nInstead of using “customer first” as a slogan (they are often actually “company first”), C2B companies are truly “customer first” by design.\nThe author offers four general principles for C2B-aligned operations:\n\nDevelop a smart network. C2B companies are usually “smart businesses” leveraging network coordination and data intelligence.\nDesign the right internet interface. C2B is usually more pull than push, so customers need an interface where they can share their needs and feedback, ideally in real time and at very low cost.\nBuild a C2B beachhead. Start with one module that can get the momentum going.\nUse the capabilities of platforms.\n\n\n\nPositioning\nEcosystems built around smart business are described with a new framework: points, lines and planes.\nTraditional positioning asks: Who are your customers? What are your value propositions? How is your positioning different from that of your competitors?\nIn response to this, Michael Porter proposed three positioning strategies: cost leadership, differentiation and niche.\nWithin a smart network positioning is described differently, internally in Alibaba a geometrical analogy is used:\n\nPoints are individuals or firms with specialized skills providing functional services but that can’t survive on their own (e.g., factories, designers, models, etc.)\nLines use the services provided by points and planes to create products and services combining productive functions and capabilities. For example, a web celeb incubator or even the web celebs.\nPlanes are platforms like Taobao that provide infrastructural services and help new lines to form and grow.\n\nEach have different value propositions and competitive advantages. For example, while the competitive advantage of points is often expertise, lines have value/cost/efficiency and planes have to be good at matching.\nWith this framework, the author explains that when Taobao is compared to Amazon, it is being mistakenly classified as a line firm when it is actually a plane.\nTraditionally, points have been absorbed into larger organizations to reduce transaction costs, but planes reduce the costs and create markets for easy exchange of skills. It is also now much easier for them to scale up and become profitable very quickly.\nIt is also important to understand that points, lines and planes are interdependent. Players that try to build their business model on their own will probably be outplayed by players that leverage the network effectively."
  },
  {
    "objectID": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html#part-three---how-smart-businesses-run-organizational-implications",
    "href": "posts/2021-04-18-smart-business/2021-04-18-smart-business.html#part-three---how-smart-businesses-run-organizational-implications",
    "title": "Smart Business",
    "section": "Part three - How smart businesses run: Organizational implications",
    "text": "Part three - How smart businesses run: Organizational implications\nWith a new strategic framework, it is natural for management to also evolve.\n\nSelf-tuning\n\nThe classical approach of analyze, plan, and execute is much too slow and inflexible for today’s environment. Instead of formal planning, strategy formulation is the constant and rapid iteration between vision and action.\n\nThe idea of self-tuning is borrowed from the iterative learning of machine learning algorithms. Strategic departments shift their focus towards creating a continuous loop of experimentation and learning.\nAlibaba discovered that they did not know enough about the future to plan for the next few years. There was a real need to allow the company to adjust and adapt in real time, without traditional management getting in the way.\nComputer algorithms do not program themselves, it is humans that must decide their objective function which defines how the algorithm prioritizes different directions toward that goal.\nIn Alibaba, mission is defined as a relatively fixed reason to exist while the vision corresponds to a mutable, improvable view of the future.\nFor a company, the equivalent of an objective function is the vision. It sets the direction of the evolution the firm and the network it belongs to.\nAs time passes, the vision has to be checked against reality and updated. The objective function may need to be re-calibrated, improved or changed.\nA powerful example of this experimentation mentality comes from 2011, when there was a heated internal debate on which business model to build up.\nManagement decided to split the successful business into three independent and competing units (Tmall, Taobao & Etao) and let the market pick the future winners. By 2013, Tmall was the clear market leader.\nIt was a hard decision, with high organizational and financial costs. Explaining the experiment to employees and what they were trying to learn was crucial.\n\nInstead of micromanaging the firm, management creates the organization’s architecture to run itself.\n\nThe book covers examples on how smart business applied this new strategic focus in the areas of\n\nPeople. The success of smart business depends on creative workers making mission and culture even more important.\nInfrastructure. The right infrastructure is needed to enable people instead of simply manage them. For example, in many companies and teams the cost of experimentation is prohibitive.\nMechanisms. Coordination mechanisms such as software or platforms that enable teams to collaborate with each other.\n\n\n\nThe future of smart business\nThe last chapter summarizes many of the lessons from Alibaba’s experience.\nA repeating theme in these experiences and throughout the book is the importance of feedback loops.\nFeedback is necessary for effective learning and fast feedback loops speed up learning.\nAnother important concept is ecosystem, which the author admits has been overused the last few decades. It is still a useful metaphor because strategy for platforms is interconnected instead of isolated and reactive instead of planned.\nThe speed in which the world changes is accelerating. This makes it very difficult to predict the future, and this makes it even more important to try to find a clear view of the future. This process of visioning is something anyone can do and we can then self-tune by testing our vision with actions that give us relevant feedback.\nSimilar to the knowledge revolution described by Peter Drucker, management at Alibaba see a creativity revolution in progress. Innovation and human creativity become key components of producing value while routine work, including information processing will have decreasing value.\nPlatforms succeed when they help individuals grow and succeed. For example, the web-celeb example shows how someone with limited earning power and freedom working for a large company as a normal in-house model can become a freelancer and then a brand owner through the Taobao platform."
  },
  {
    "objectID": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html",
    "href": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html",
    "title": "Deep Learning - Notes",
    "section": "",
    "text": "A short summary of DL fundamentals."
  },
  {
    "objectID": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html#what-is-a-perceptron",
    "href": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html#what-is-a-perceptron",
    "title": "Deep Learning - Notes",
    "section": "What is a perceptron?",
    "text": "What is a perceptron?\n\nPerceptrons were originally brain models created to understand how the brain works. A perceptron as we know it encodes several principles about how the brain works and then evolved into an algorithm for supervised binary classification.\n\nIn the 1960’s, Frank Rosenblatt published the book Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. It is curious that this fundamental block for AI was, in the author’s mind, a tool for understanding the human brain and not for pattern recognition (even though he encouraged this use as well):\n\nFor this writer, the perceptron program is not primarily concerned with the invention of devices for “artificial intelligence”, but rather with investigating the physical structures and neurodynamic principles which underlie “natural intelligence”. A perceptron is first and foremost a brain model, not an invention for pattern recognition [emphasis added]” (p. viii).\n\nIn other words, the perceptron is actually a simplification and abstraction which has allowed us to discover principles for how the brain works. These same principles were then also used to create pattern recognition machines.\nRosenblatt explicitly recognizes that his model is a direct descendant of the model created by McCulloch and Pitts, and influenced by the theories of Hebb and Hayek.\nMain components of a perceptron in Rosenblatt’s book: - Environment: The environment generates the information that is initially passed on to the perceptron.\n\nSignal generating units: Each unit receives a signal and generates an output signal.\nSignal propagation functions: These are rules that define how signals are generated and transmitted.\nMemory functions: These are rules that define how properties of the perceptron can be changed in response to certain activity.\n\nThe definition of a single neuron evolves from the ideas above.\nA neuron takes values from its environment (e.g. x1, x2, x3) and each of these gets multiplied by a stored parameter (e.g. w1, w2, w3). The sum of each of these operations is then passed through an activation function.\nIn other words, it’s as if we are trying to pass a signal through the neuron and all of these components work together to establish how the signal is transmitted.\nWe can imagine three old batteries used to turn on a machine. Turning it on with too little energy could cause it to break, so we check the current before passing it on to the machine.\n\n\n\nPerceptron\n\n\nIn the example below, we are randomly initializing the parameters. The activation function is a step-function with a threshold of 4. This means that the signal is only passed on as a unitary value if it is larger than or equal to the threshold.\n\n\nCode\nimport numpy as np\n\nw1 = np.random.random()*2 # generates random floats between 0 and 2\nw2 = np.random.random()*2\nw3 = np.random.random()*2 \n\nprint(f'W1 is equal to: {w1}')\nprint(f'W2 is equal to: {w2}')\nprint(f'W3 is equal to: {w3}\\n')\n\nx1 = 2\nx2 = 1\nx3 = 3\nb = 0\n\nactivation_function = lambda x: 1 if x &gt;=4 else 0\n\noutput = activation_function(x1*w1 + x2*w2 + x3*w3)\n\nprint('Output:', output)\n\nif output == 1:\n    print('The machine is on!')\nelse:\n    print('Not enough energy to turn on the machine :(')\n\n\nW1 is equal to: 0.6321002815675523\nW2 is equal to: 1.6995522179113192\nW3 is equal to: 1.2072466687862997\n\nOutput: 1\nThe machine is on!"
  },
  {
    "objectID": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html#what-is-an-activation-function",
    "href": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html#what-is-an-activation-function",
    "title": "Deep Learning - Notes",
    "section": "What is an activation function?",
    "text": "What is an activation function?\nGoing back to Rosenblatt’s book, activation functions are essentially signal propagation functions.\nWhen a neuron receives a signal, the activation function decides if the signal is passed on and how strong the output signal becomes.\nWe already learned about the step function. This activation is often not ideal for multiple reasons.\nFirst of all, the result is binary. But sometimes we are more interested in also knowing the degree of certainty, so I probability might be better.\nWe might also want to have a wider range of values. When predicting age, for example, binary values of 0 or 1 will be of little value.\nA lot of different activation functions have been developed by researchers. Three common activation functions are:\nSigmoid function Has a great property of having outputs between 0 and 1 and therefore can be interpreted as probabilities. The function is also smooth and easy to differentiate which makes learning easier.\nIt can be problematic when the input signal has very large positive or negative values. At those points the derivative is very close to 0 and learning becomes very slow.\nHyperbolic function This is another smooth function with a range of values between -1 and 1. This is interesting because sometimes a signal might have a reverse effect on the output and the hyperbolic function allows us to include this type of relationship in the network.\nRectified linear unit (ReLU) This function is very simple aned fast to compute. This allows us to work with larger and more complex models that, given enough data, can produce better results overall."
  },
  {
    "objectID": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html#what-is-a-neural-network",
    "href": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html#what-is-a-neural-network",
    "title": "Deep Learning - Notes",
    "section": "What is a neural network?",
    "text": "What is a neural network?\n\nA neural network is a directed system of connected neurons which is capable of propagating a signal received from the environment and produces an output signal.\n\nThe neurons are generally organized in different layers which allow us to break free from linearity.\nLinearity means that we are also assuming monotonicity. In other words, an increase in an input value always increases the output value if the corresponding weight is positive (and will always decrease the output value if the weight is negative).\nThis works fine in examples like the one seen above where we turn on a lightbulb depending on how much energy we get from each battery.\nBut this makes less sense in other cases. For examples very pronounced sales spikes in an online marketplace followed by no sales at all could be indicative of fraud. A positive value for a feature describing this type of spikes should increase the probability of fraud.\nBut is this always the case?\nWhat if we additionally know that the owner of the store is a web celeb (网红) on Alibaba? In that case the spikes above are expected, and therefore a positive value for this feature should decrease the probability of fraud while any other behavior might be suspicious.\nLet’s build a neural network step by step:\nThe simplest example is a single neuron with only one parameter which does not modify the signal in any way:\n\n\nCode\ndef nn(x, w):\n    return w*x\n\nprint(nn(3, 6))\n\n\n18\n\n\nMost processes we find in the real world are not this simple. We need to take into account multiple input features.\nI love music, imagine I want to predict if I will like a particular song or not. We can quickly multiply each input value by its corresponding weight using a dot product.\n\n\nCode\ndef nn(X, W):\n    return W.dot(X)\n\nx1 = 3.5 # length of songs in minutes\nx2 = 0 # binary value indicating if the genre is jazz or not\nx3 = 0 # binary value indicating if the artist is Nicki Minaj or not\nx4 = 1 # binary value indicating if the artist is Alan Walker\n\nX = np.array([x1, x2, x3, x4])\nW = np.array([1., 0.3, -3, 4])\n\nprint(nn(X, W))\n\n\n7.5\n\n\nWhat is interesting above is that the weights actually encode certain information about my taste in music. I really don’t like when a song is too short and, in general, I’m not fond of music by Nicki Minaj (notice the negative weight). But I do love music by Alan Walker. Jazz is nice but I don’t love it.\nNow the real question is, how do we know the values of these weights. In this case, I used my deep expertise regarding my own music taste to set the weights. But we would usually be more interested in doing this for the users of our streaming platform at scale. Millions of people we have never and will probably never meet in person.\nSo, first we’re going to change the output. We want to predict if a particular user is going to like a song or not. Using the sigmoid function we can directly compare the true values (0 or 1) to our predictions (floats between 0 and 1).\nWe will also initialize the weights randomly and print out an error value showing how close our prediction is to the true value:\n\n\nCode\n\ndef nn(X, y, W): \n    prediction = W.dot(X)\n    error = y-prediction\n    \n    print('Predicted value:', round(prediction, 3))\n    print('Error:', round(error, 3))\n\nx1 = 3.5 # length of songs in minutes\nx2 = 0 # binary value indicating if the genre is jazz or not\nx3 = 0 # binary value indicating if the artist is Nicki Minaj or not\nx4 = 1 # binary value indicating if the artist is Alan Walker\n\nX = np.array([x1, x2, x3, x4])\ny = 5\nW = np.random.random(size=4)*2-1\n\nnn(X, y, W)\n\n\nPredicted value: -1.468\nError: 6.468\n\n\nIt’s now time to start talking about learning or how our neural network is going to choose the best parameters during training to make accurate predictions.\nWe will follow a very simple framework of three steps:\n\nPredict\nCompare\nLearn\n\nThis time we will add multiple iterations to our algorithm and we will do the three steps above during each iteration.\n\n\nCode\ndef nn(X, y, W): \n    print(f'True value: {y}\\n')\n    \n    for i in range(10):\n        prediction = W.dot(X)\n        error = y-prediction\n\n        print('Predicted value:', round(prediction, 3))\n        print('Error:', round(error, 3))\n        \n        if error &gt; 0:\n            W += 0.01\n        else:\n            W -= 0.01  \n\nx1 = 3.5 # length of songs in minutes\nx2 = 0 # binary value indicating if the genre is jazz or not\nx3 = 0 # binary value indicating if the artist is Nicki Minaj or not\nx4 = 1 # binary value indicating if the artist is Alan Walker\n\nX = np.array([x1, x2, x3, x4])\ny = 1\nW = np.random.random(size=4)*2-1\n\nnn(X, y, W)\n\n\nTrue value: 1\n\nPredicted value: 0.116\nError: 0.884\nPredicted value: 0.161\nError: 0.839\nPredicted value: 0.206\nError: 0.794\nPredicted value: 0.251\nError: 0.749\nPredicted value: 0.296\nError: 0.704\nPredicted value: 0.341\nError: 0.659\nPredicted value: 0.386\nError: 0.614\nPredicted value: 0.431\nError: 0.569\nPredicted value: 0.476\nError: 0.524\nPredicted value: 0.521\nError: 0.479\n\n\nHere we are doing hot & cold learning. After each prediction we are making a comparison just like in the classical game so that we get “hotter” or closer to the true answer after each guess.\nThe way we are calculating the error makes it negative if it was too high or positive if our guess was too low.\nWe can now be a bit smarter in the way we learn. Instead of guessing and trying to jiggle the output to both sides, we can use the gradient to guide us:\n\n\nCode\ndef nn(X, y, W): \n    print(f'True values: {y}\\n')\n    n = y.shape[1]\n    \n    for i in range(100):\n        predictions = W.dot(X.T)\n        mse = (1/2)*np.mean((y-predictions)**2)\n        \n        if i % 10 == 0:\n            print('Mean Squared Error:', round(mse, 3))\n        \n        dW = -(1/n)*(y-predictions).dot(X)\n        W -= 0.1*dW\n          \n    print('\\nW:', np.round(W, 3))\n    print('\\nFinal predictions:', np.round(predictions, 2))\n\nX = np.array([[1, 0],\n              [0, 1],\n              [0, 0],\n              [1, 1]])\n\ny = np.array([[1, 0, 0, 1]])\nW = np.random.randn(1, 2)\n\nnn(X, y, W)\n\n\nTrue values: [[1 0 0 1]]\n\nMean Squared Error: 0.234\nMean Squared Error: 0.132\nMean Squared Error: 0.078\nMean Squared Error: 0.046\nMean Squared Error: 0.028\nMean Squared Error: 0.017\nMean Squared Error: 0.01\nMean Squared Error: 0.006\nMean Squared Error: 0.004\nMean Squared Error: 0.002\n\nW: [[0.927 0.073]]\n\nFinal predictions: [[0.92 0.07 0.   1.  ]]\n\n\nThis version led us quickly very close to the correct answers. But we now have another problem. The previous problem was very easy to learn because one of the features had a direct 1-on-1 relationship with an output. A simple linear function was capable of leveraging that feature.\nLet’s look at the next example:\n\n\nCode\nX = np.array([[1, 0],\n              [0, 1],\n              [0, 0],\n              [1, 1]])\n\ny = np.array([[1, 1, 0, 0]])\nW = np.random.randn(1, 2)\n\nnn(X, y, W)\n\n\nTrue values: [[1 1 0 0]]\n\nMean Squared Error: 0.863\nMean Squared Error: 0.572\nMean Squared Error: 0.408\nMean Squared Error: 0.311\nMean Squared Error: 0.254\nMean Squared Error: 0.219\nMean Squared Error: 0.198\nMean Squared Error: 0.186\nMean Squared Error: 0.178\nMean Squared Error: 0.174\n\nW: [[0.462 0.204]]\n\nFinal predictions: [[0.47 0.2  0.   0.67]]\n\n\nMSE might not be extremely high but the answers are terrible. This is because the new problem we’re working with cannot be solved with a simple linear function. So, to solve this we can add a hidden layer with an activation function (more on why this works can be found further down):\n\n\nCode\nnp.random.seed(2)\n\ndef relu(x):\n    return (x&gt;0)*x\n\ndef relu_prime(x):\n    return x&gt;0\n\ndef nn(X, y, hidden_size , lr=0.01): \n    print(f'True values: {y}\\n')\n    n = y.shape[1]\n    \n    W1 = np.random.randn(X.shape[1], hidden_size)\n    W2 = np.random.randn(hidden_size, 1)\n    \n    for i in range(100):\n        z1 = X.dot(W1)\n        a1 = relu(z1)\n        \n        z2 = a1.dot(W2) # predictions\n        mse = (1/2)*np.mean((y-z2)**2)\n        \n        if i % 10 == 0:\n            print('Mean Squared Error:', round(mse, 3))\n        \n        dZ2 = (y-z2)\n        dW2 = a1.T.dot(dZ2)\n        W2 += lr*dW2\n        \n        dZ1 = (dZ2.dot(W2.T))*relu_prime(a1)\n        dW1 = X.T.dot(dZ1)\n        W1 += lr*dW1 #(1/n)\n    \n    print('\\nW1:', np.round(W1, 3))\n    print('W2:', np.round(W2, 3))\n    \n    print('\\nFinal predictions:', np.round(z2, 2))\n\nX = np.array([[1, 0],\n              [0, 1],\n              [0, 0],\n              [1, 1]])\n\ny = np.array([[1, 1, 0, 0]]).T\n\nnn(X, y, 4)\n\n\nTrue values: [[1]\n [1]\n [0]\n [0]]\n\nMean Squared Error: 1.12\nMean Squared Error: 0.284\nMean Squared Error: 0.133\nMean Squared Error: 0.078\nMean Squared Error: 0.052\nMean Squared Error: 0.037\nMean Squared Error: 0.027\nMean Squared Error: 0.021\nMean Squared Error: 0.016\nMean Squared Error: 0.012\n\nW1: [[-0.417 -0.056 -2.136  0.599]\n [-1.793 -0.842  0.847 -1.302]]\nW2: [[-1.058]\n [-0.909]\n [ 0.876]\n [ 1.738]]\n\nFinal predictions: [[1.04]\n [0.74]\n [0.  ]\n [0.  ]]"
  },
  {
    "objectID": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html#what-is-universality",
    "href": "posts/2021-03-01-dl-notes/2021-03-01-dl-notes.html#what-is-universality",
    "title": "Deep Learning - Notes",
    "section": "What is universality?",
    "text": "What is universality?\n\nUniversality is the ability to compute any arbitrary function.\n\nIt has been proven that any function we can think of can be approximated by a neural network with at least two layers.\nMichael Nielsen clarifies two caveats related to this idea of universality: 1. Universality doesn’t mean that the neural network is guaranteed to be exact, instead we are approximating the function and the more neurons we add the closer it gets to the true function. This means that for any function f(X) and any error threshold we define we can always find a neural network with output g(x) that satisfies:\n\\[ |g(x) - f(x)| &lt; \\epsilon \\]\n\nNeural networks approximate continuous functions. Functions that are not continuous with sharp and sudden jumps won’t be approximated by a neural network as a general rule. But that doesn’t mean that we can often use a continuous approximation that is good enough for our given purposes when trying to approximate a discontinuous function."
  }
]